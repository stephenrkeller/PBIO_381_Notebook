## Author: Ethan Thibault     
## Ecological Genomics:   

### Overall Description of notebook      

This notebook will catalogue my entries throughout the semester, including all of my code, results and interpretations.

### Date started: 2018-01-04
### Date end:   (year-month-day)    

### Philosophy   
Science should be reproducible and one of the best ways to achieve this is by logging research activities in a notebook. Because science/biology has increasingly become computational, it is easier to document computational projects in an electronic form, which can be shared online through Github.    

### Helpful features of the notebook     

**It is absolutely critical for your future self and others to follow your work.**     

* The notebook is set up with a series of internal links from the table of contents.    
* All notebooks should have a table of contents which has the "Page", date, and title (information that allows the reader to understand your work).     
* Also, one of the perks of keeping all activities in a single document is that you can **search and find elements quickly**.     
* Lastly, you can share specific entries because of the three "#" automatically creates a link when the notebook renders on github.      


<a rel="license" href="http://creativecommons.org/licenses/by/4.0/"><img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by/4.0/88x31.png" /></a><br />This work is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution 4.0 International License</a>.  


### Table of contents for 60 entries (Format is *Page: Date(with year-month-day). Title*)        
* [Page 1: 2018-01-24](#id-section1). Intro to Github, RMarkdown, and UNIX command-line
* [Page 2: 2018-01-26](#id-section2). Familiarizing myself with UNIX command-line homework
* [Page 3: 2018-01-29](#id-section3). Working with RNA-Seq data (day one)
* [Page 4: 2018-01-31](#id-section4). Working with RNA-Seq data (day two)
* [Page 5: 2018-02-05](#id-section5). Working with RNA-Seq data (day three)
* [Page 6: 2018-02-06](#id-section6). Working with RNA-Seq data (day four)
* [Page 7: 2018-02-12](#id-section7). Working with RNA-Seq data (day five)
* [Page 8:](#id-section8). Working with RNA-Seq data (day six)
* [Page 9:](#id-section9). Population Genomics 1: Intro to SNP and Genotype Calling
* [Page 10:](#id-section10). Population Genomics 2: Diversity and Site Frequency Spectrum (SFS)
* [Page 11:](#id-section11). Population Genomics 3: Admixture and Population Structure
* [Page 12:](#id-section12). 
* [Page 13:](#id-section13). Code for Assignment One
* [Page 14:](#id-section14).
* [Page 15:](#id-section15).
* [Page 16:](#id-section16).
* [Page 17:](#id-section17).
* [Page 18:](#id-section18).
* [Page 19:](#id-section19).
* [Page 20:](#id-section20).
* [Page 21:](#id-section21).
* [Page 22:](#id-section22).
* [Page 23:](#id-section23).
* [Page 24:](#id-section24).
* [Page 25:](#id-section25).
* [Page 26:](#id-section26).
* [Page 27:](#id-section27).
* [Page 28:](#id-section28).
* [Page 29:](#id-section29).
* [Page 30:](#id-section30).
* [Page 31:](#id-section31).
* [Page 32:](#id-section32).
* [Page 33:](#id-section33).
* [Page 34:](#id-section34).
* [Page 35:](#id-section35).
* [Page 36:](#id-section36).
* [Page 37:](#id-section37).
* [Page 38:](#id-section38).
* [Page 39:](#id-section39).
* [Page 40:](#id-section40).
* [Page 41:](#id-section41).
* [Page 42:](#id-section42).
* [Page 43:](#id-section43).
* [Page 44:](#id-section44).
* [Page 45:](#id-section45).
* [Page 46:](#id-section46).
* [Page 47:](#id-section47).
* [Page 48:](#id-section48).
* [Page 49:](#id-section49).
* [Page 50:](#id-section50).
* [Page 51:](#id-section51).
* [Page 52:](#id-section52).
* [Page 53:](#id-section53).
* [Page 54:](#id-section54).
* [Page 55:](#id-section55).
* [Page 56:](#id-section56).
* [Page 57:](#id-section57).
* [Page 58:](#id-section58).
* [Page 59:](#id-section59).
* [Page 60:](#id-section60).

------
<div id='id-section1'/>
### Page 1: 2018-01-24. Notes on using Github, Rmarkdown, and the UNIX command-line

Today we created our GitHub repos for the course and began our notebooks.

Other goals for today:

* publish our notebooks to GitHub
* log into the UNIX server

------
<div id='id-section2'/>
### Page 2: 2018-01-26. Familiarizing myself with UNIX command-line homework

As a homework assignment, I will log back into the pbio381 server, familiarize myself with some of the commands, and make this notebook post that I will push to my GitHub notebook.

What did I do:

* open terminal
* enter "ssh eathibau@pbio381.uvm.edu" and then enter password
* next I perused my files using cd to change directory and ll to view files within those directories
* entered pwd to see current directory
* I also realized that if you want to change to a new directory, you need to be above that in the hierarchy of files. If you aren't you can use "cd .." to move back or "cd /" but this brings you really far back.
* I got lost going back to the root because my permission was denied once I started entering the letter directories so I couldn't see where to go next. Luckily in class I wrote what my ~ stood for "/users/e/a/eathibau" although now I am realizing I probably could have wrote "cd ~"
* Yes "cd ~" works from the root

At the risk of creating files that will clutter up my directories and confuse me in the future, I will abstain from doing that in this assignment and focus on moving around the directory, seeing what is there and problem solving how to move where I want to be.

------
<div id='id-section3'/>
### Page 3: Working with RNA-Seq data (day one)

#### Experimental Setup

#### Populations

* Italy (IT)
* Western Australia (WA)
* North Carolina (NC)

#### Developmental Stages

* L3L
* PP1
* PD1
* AD4

#### Sex

* Male
* Female

3 pops X 4 developmental stages X 2 sexes X 3 individuals = 72 samples

Sequenced on about 7 lanes of Illumina HiSeq 2500

#### Viewing File

View first four lines of my file:

zcat WA_PP1_F1_AGTCAA_L003_R1_001.fastq.gz | head -n4

Output:

@CCRI0219:155:C2LNBACXX:3:1101:1499:1976 1:N:0:AGTCAA
CGGGATCGTAAGGAGCTAATTCTTTAGCACGGGATGTTTTTACTAAATCAACCCATTCCGGTACTTTTAGTTTTCCTGATTTTTTAAGAAATTGGGCGAA
+
@@?DDDDDFFH??FHBHGI4CB?FHGH>@<EGG@DEHHIGIEFHE>DH9CC3B;;7@CCEBHEDEDEDE@ACAC;>@CCCCCCFBBA>@C9A:>@?B><@

Line 1: begins with @ and then information about the read

Line 2: the actual DNA sequence

Line 3: always begins with a +

Line 4: quality scores

P is the probability that a base pair call was an error and then converted to Q score on a scale of 0 to 40

#### Visualize using FastQC

This makes the fastqc file, using the path to the file and then use -o to specify an output directory (the directory must be created beforehand (using mkdir).

This gives you a summary of all the data.

fastqc /data/project_data/beetles/rawdata/WA_PP1_F1_AGTCAA_L003_R1_001.fastq.gz -o ~/Fastqc_output/

Open/view the html output file via Fetch

* pbio381.uvm.edu
* uvm netid
* password

Open/view the html output file via scp command

* Open new terminal
* change directory to where I want to download the file to my local computer
* use scp command:

ip0af527d4:~ ethanthibault$ cd /Users/ethanthibault/Documents/UVM_2018/PBIO381/PBIO_381_Notebook 
ip0af527d4:PBIO_381_Notebook ethanthibault$ scp eathibau@pbio381.uvm.edu:~/Fastqc_output/WA_PP1_F1_AGTCAA_L003_R1_001_fastqc.html .
eathibau@pbio381.uvm.edu's password: 
WA_PP1_F1_AGTCAA_L003_R1_001_fastqc.html      100%  350KB   6.8MB/s   00:00    
ip0af527d4:PBIO_381_Notebook ethanthibault$ 

* the (.) after the html file places it in my current directory where I can now open it

------
<div id='id-section4'/>
### Page 4: Working with RNA-Seq data (day two)

Use "vim" command to open up and view trim_example.sh file

cp /data/scripts/trim_example.sh ~/scripts/

Edit things in vim using "i" then hit esc (leaves edit mode) and enter ":wq" to write and escape.

* ":" allows you to enter commands
* "w" allows you to write
* "q" quits vim
* "w trim_F1.sh" allows you to rename file

The new file was written to the current directory and use the following code to make it executable:

chmod u+x trim_F1.sh

* "u" means owner
* "x" makes it executable

Making scripts like this allows you to run one command in the terminal to execute many different lines of code.

Use fastqc command to view these files.

Use Fetch to open it, but also scp to move it to my local drive:

scp eathibau@pbio381.uvm.edu:~/Fastqc_output/*html .

#### Mapping Reads

* Download reference transcriptome and make an index (Steve and Melissa already did this)
* Enter Screen with "screen"
* Run your command
* leave screen with "cntl+a+d"

This allows you to quit terminal and close/shutoff computer without it ending

------
<div id='id-section5'/>
### Page 5: Working with RNA-Seq data (day three)

- Save last 100 lines as tail.sam
- open with vim
- get rid of wrapping in vim

tail -n 100 WA_PP1_F1_bwamem.sam > tail.sam

vim tail.sam

:set nowrap

#### This is how you interpret the sam file

In order of columns from left to right

- the read, aka. query, name,
- a FLAG (number with information about mapping success and orientation and whether the read is the left or right read),
- the reference sequence name to which the read mapped
- the leftmost position in the reference where the read mapped
- the mapping quality (Phred-scaled)
- a CIGAR string that gives alignment information (how many bases Match (M), where there’s an Insertion (I) or Deletion (D))
- an ‘=’, mate position, inferred insert size (columns 7,8,9),
- the query sequence and Phred-scaled quality from the FASTQ file (columns 10 and 11),
- then Lots of good information in TAGS at the end, if the read mapped, including whether it is a unique read (XT:A:U), the number of best hits (X0:i:1), the number of suboptimal hits (X1:i:0).

Use grep to try and find flags

grep -c X0:i:1 WA_PP1_F1_bwamem.sam

The -c gives you the count of that flag

Use "man" to get the manual for a command

man grep





Use samtools to see a summary of how well our reads mapped to the reference

samtools flagstat WA_PP1_F1_bwamem.sam

------
<div id='id-section6'/>
### Page 6: Working with RNA-Seq data (day four)

BASH

- make a bash file "vim test_bash"
- shift i allows you to alter the script
- put "#! /bin/bash/"
- type stuff
- alter accessibility "chmod u+x test_bash"
- open file "./test_bash"  the . is the current directory
- rename it with the .sh at the end "mv ./test_bash ./test_bash.sh"

To move the two files from the server to my local computer I open a new terminal, drag the folder to set directory.

------
<div id='id-section7'/>
### Page 7: Working with RNA-Seq (day five)

Here is my current code for the the DESeq2. I did not have what Melissa had on the projector.

If that is too difficult to read, [this](DESeq2.R) is hopefully a functional link to my R code



##### set working directory

setwd("~/Documents/UVM_2018/PBIO381/PBIO_381_Notebook")

library("DESeq2")

library("ggplot2")

countsTable <- read.delim("allcountsdataRN_noIT.txt", header=TRUE, stringsAsFactors = TRUE, row.names = 1)

countData <- as.matrix(countsTable)

head(countData)

conds <- read.delim("cols_data_noIT.txt", header=TRUE, stringsAsFactors =  TRUE, row.names = 1)

head(conds)

colData <- as.data.frame(conds)

#########################################

dds <- DESeqDataSetFromMatrix(countData = countData, colData = colData, design = ~devstage + sex + population)

##### "population effect" model controlling for differences in devstage and sex

dim(dds)

##### [1] 17483    48

dds <- dds[rowSums(counts(dds)) > 1,]

dim(dds)

##### [1] 16851    48     Okay, nice, only lost about 600 genes

dds <- DESeq(dds, modelMatrixType = "standard")

resultsNames(dds)

##### [1] "Intercept"           "devstage_L3L_vs_AD4" "devstage_PD1_vs_AD4" "devstage_PP1_vs_AD4" "sex_M_vs_F"    

##### [6] "population_WA_vs_NC"

res <- results(dds)

str(res)

res <- res[order(res$padj),]

head(res)

##### log2 fold change (MLE): population WA vs NC 
##### Wald test p-value: population WA vs NC 
#####DataFrame with 6 rows and 6 columns
##### baseMean log2FoldChange     lfcSE      stat       pvalue         padj
##### <numeric>      <numeric> <numeric> <numeric>    <numeric>    <numeric>
#####   OTAU017482-RA 126.291608     -5.4166340 0.6732174 -8.045892 8.561964e-16 1.268369e-11
##### OTAU012716-RA 188.877675      4.2644034 0.5427535  7.856980 3.935069e-15 2.914706e-11
##### OTAU008667-RA 231.871115     -0.8736955 0.1267134 -6.895051 5.384538e-12 1.994164e-08
##### OTAU012562-RA 251.774364     -0.8774079 0.1270957 -6.903520 5.072966e-12 1.994164e-08
##### OTAU013988-RA   4.416955      4.4229857 0.6836393  6.469765 9.815559e-11 2.908154e-07
##### OTAU011160-RA  10.241516     -2.5149390 0.4125305 -6.096371 1.085033e-09 2.678947e-06

summary(res)

##### out of 16851 with nonzero total read count
##### adjusted p-value < 0.1
##### LFC > 0 (up)     : 333, 2% 
##### LFC < 0 (down)   : 282, 1.7% 
##### outliers [1]     : 85, 0.5% 
##### low counts [2]   : 1952, 12% 
##### (mean count < 1)
##### [1] see 'cooksCutoff' argument of ?results
##### [2] see 'independentFiltering' argument of ?results

res_pop <- results(dds, name="population_WA_vs_NC", alpha=0.05)

res_pop <- res_pop[order(res_pop$padj),]

summary(res_pop)

######################## Data visualization

plotMA(res_pop, main="DESeq2",ylim=c(-2,2))

abline(h=c(-1,1), col="blue", lwd=2)

##### sex effect?

res_sex <- results(dds, name="sex_M_vs_F", alpha=0.5)

plotMA(res_sex, main="DESeq2",ylim=c(-2,2))

abline(h=c(-1,1), col="blue", lwd=2)

######## PCA

vsd <- vst(dds,blind=FALSE)

data <- plotPCA(vsd,intgroup=c("population","devstage","sex"), returnData=TRUE)

percentVar <- round(100 * attr(data, "percentVar"))

data$devstage <- factor(data$devstage, levels=c("L3L","PP1","PD1","AD4"), labels = c("L3L","PP1","PD1","AD4"))

pdf(file="PCA_sex_by_stage.pdf",height=5.5,width=5.5)

ggplot(data,aes(PC1,PC2,color=sex,shape=devstage)) +
  geom_point(size=4,alpha=0.85) +
  xlab(paste0("PC1: ",percentVar[1],"% variance")) +
  ylab(paste0("PC2: ",percentVar[2],"% variance")) +
  theme_minimal()
  
dev.off()

ggplot(data,aes(PC1,PC2,color=population,shape=devstage)) +
  geom_point(size=4,alpha=0.85) +
  xlab(paste0("PC1: ",percentVar[1],"% variance")) +
  ylab(paste0("PC2: ",percentVar[2],"% variance")) +
  theme_minimal()**



------
<div id='id-section8'/>
### Page 8: Working with RNA-Seq data (day sex)



------
<div id='id-section9'/>
### Page 9: Population Genomics 1: Intro to SNP and Genotype Calling

Goals:

1. Take sequence alignment files (sam) and extract mapping stats & read depth coverage
2. Convert sam to binary (bam) format, and use samtools/bcftools for SNP detection
3. Learn Variant Call Format (vcf) for storing SNP genotypes
4. Begin to evaluate filtering strategies for determining high-quality SNPs for downstream analyses

Where we've been:

Started with raw reads. Then using trimmomatic produced clean reads. Next we mapped to the reference genome using bwa to get sam files. Then we used the python script to obtain a counts file. Next, we used DESeq2 to identify differentially expressed genes. Then we did companion analyses like enrichment and WGCNA.

Now we are going back to our sam files for pop gen studies. First we will call SNPs and genotypes. We can use samtools (used more frequently) and reads2SNPs (used less frequently but has handy paralog filtering). Then once we have SNPs we need to use quality control to identify useful SNPs and genotypes with vcftools. Once we have SNPs and genotypes that are reliable we can find pop gen statistics like pi, Tajima's D, structure selection etc.

1. Convert from sam >> bam (binary file that is more condensed but unreadable)
2. Check mapping stats
3. Fix reads that are no longer mated (paired)
4. Remove duplicates (takes awhile)
5. Index for computational efficiency
6. Use the companion program bcftools to call SNPs and genotypes

Move to folder with sam file

"WA_PP1_F1_bwamem.sam"

type vi to open vim and type i to edit the form.

put in shebang "#!/bin/bash" This tells it to read it in bash language

samtools (use samtools program) view (opens file) -b (export in binary) -@ 4 (use four CPUs) WA_PP1_F1_bwamem.sam (file name) -o (output file name) WA_PP1_F1_bwamem.bam

Steve provided a manual for samtools on the github page.

samtools flagstat (gives you a summary of the kinds of fixes that need to be done) WA_PP1_F1_bwamem.bam (filename)

samtools depth WA_PP1_F1_bwamem.bam (gives you the number of reads at each position)

samtools fixmate WA_PP1_F1_bwamem.bam WA_PP1_F1_bwamem.fixmate.bam (this fixes mate pais between paired end reads that have been orphaned, input file then output file)

samtools sort -@4 WA_PP1_F1_bwamem.fixmate.bam WA_PP1_F1_bwamem.fixmate.sorted.bam (sort alignments using 4 CPUs: input file then output file)

samtools rmdup WA_PP1_F1_bwamem.fixmate.sorted.bam WA_PP1_F1_bwamem.fixmate.sorted.rmdup.bam (this removes pcr duplicates with input and output file. we aren't doing it becasue it takes a while but should typically do it)

samtools index WA_PP1_F1_bwamem.fixmate.sorted.bam (this indexes our final alignment for fast processing)

hit escape, ":w CallSNPs.sh" to write this bash file

":q" to quit

chmod o+x CallSNPs.sh (as owner add executable function to our file)

Enter a screen to run this file in the background *control AD to quit screen

"screen"

"bash CallSNPs.sh" (run the script)

use *control AD to exit screen

samtools tview WA_PP1_F1_bwamem.fixmate.sorted.bam /data/project_data/beetles/reference/OTAU.fna (maps the reads to the reference genome)

------
<div id='id-section10'/>
### Page 10: Population Genomics 2: Diversity and Site Frequency Spectrum (SFS)

Gives you a breakdown of all of you reads:

samtools flagstat WA_PP1_F1_bwamem.fixmate.sorted.bam

Now we are going to call SNPS in our bash file

vi CallSNPs.sh

bcftools mpileup \
(gives you how many snps at each position and removes invariant sites)

A backslash (top left goes back) allows you to move to the next line

-Ou -f /data/project_data/beetles/reference/OTAU.fna \
(output data in uncompressed form)

(where to get sorted bam file)

(threads 4, skip any indels ask for allele depth and total depth)

"|" is a pipe that takes everything before it and sends it to a new command.

"call" does its best to determine genotype of each SNP

"Ov" file form

"mv" allows there to be more alleles than one at a certain site

"--format-fields GQ,GP" in phred scale gives you genotype quality

Phred (this is log base 10) --> -10log(probability correct)

">WA_PP1_F1.vcf" (output file)

bcftools mpileup \
        -Ou -f /data/project_data/beetles/reference/OTAU.fna \
        ~/mydata/sam/WA_PP1_F1_fixmate.sorted.bam \
        --threads 4 --skip-indel --annotate AD,DP | \
        bcftools call -Ov -mv --format-fields GQ >WA_PP1_F1.vcf

Now we want to run this:

bash CallSNPs.sh

VCF is the standard form for SNP data

This is where the SNP data lives:

/data/project_data/beetles/snps

-- is how to use options in vcftools

To view what is in the file without making any changes:

vcftools --vcf /data/project_data/beetles/snps/OTAU_2018_samtools.vcf 
Filter out sites with more than two alleles (again just prints what you have but doesn't change the file)

vcftools --vcf /data/project_data/beetles/snps/OTAU_2018_samtools.vcf --min-alleles 2 --max-alleles 2

Filter for 90% genotype quality (10 on Phred scale) (doesn't remove the data, just codes it as missing data)

vcftools --vcf /data/project_data/beetles/snps/OTAU_2018_samtools.vcf --min-alleles 2 --max-alleles 2 --minGQ 10

Filter for missing data (eliminate SNPs that don't have at least 80% present data)

vcftools --vcf /data/project_data/beetles/snps/OTAU_2018_samtools.vcf --min-alleles 2 --max-alleles 2 --minGQ 10 --max-missing 0.8

Add filter to remove any alleles present as only one heterozygote (1/144) (minor allele frequency filter)

vcftools --vcf /data/project_data/beetles/snps/OTAU_2018_samtools.vcf --min-alleles 2 --max-alleles 2 --minGQ 10 --max-missing 0.8 --maf 0.01

Write a new file

vcftools --vcf /data/project_data/beetles/snps/OTAU_2018_samtools.vcf --min-alleles 2 --max-alleles 2 --minGQ 10 --max-missing 0.8 --maf 0.01 --recode --out OTAU_2018_samtoolsFILTERED.vcf



------
<div id='id-section11'/>
### Page 11: Population Genomics 3: Admixture and Population Structure

Each person is testing vcf file to test outputs of samtools vs read2snps and different max missing values. Use parameters from last time but use max missing of one and --het gives summary file of genome wide heterozygosity for each individual to see which way worked best. --out produces output file

vcftools --vcf OTAU_2018_samtools.vcf  --min-alleles 2 --max-alleles 2 --maf 0.01 --minGQ 20 --max-missing 1.0 --het --out ~/myresults/samtoolsmiss1.0 

Use R from the command line to look at summary het files

"R"

"df <- read.table("samtoolsmiss1.0.het",header=T)"

"str(df)"

The F row will tell us how heterozygous it is. more negative is totally het and randomly mating F would be roughly 0. We should probably work with read2SNPs with 0.8 max missing filter

"quit()" gets you out of R

"--recode" writes new file

This is ultimately the code we ran and saved for moving forward:

vcftools --vcf OTAU_2018_reads2snps_DP10GP95.vcf  --min-alleles 2 --max-alleles 2 --maf 0.01 --max-missing 0.8 --recode --out  ~/myresults/OTAU_2018_reads2snps_DP10GP95_biallelic_MAF01_Miss0.8.vcf

Start SFS (site frequency spectra)

We are going to do it by population

use grep to grab all individuals:

"grep "IT" /data/project_data/beetles/metadata/cols_data.txt"

saves file and use cut to take what i grabbed with grep and just one column

"grep "IT" /data/project_data/beetles/metadata/cols_data.txt | cut -f 1"

give it a file to save as

"grep "IT" /data/project_data/beetles/metadata/cols_data.txt | cut -f 1 >IT.inds"

Use vcf tools to pull sites only from IT individuals and calculate frequencies. out of IT makes sure IT goes into output file name

"vcftools --vcf OTAU_2018_reads2snps_DP10GP95_biallelic_MAF01_Miss0.8.vcf.recode.vcf  --keep IT.inds --freq2 --out IT"

------
<div id='id-section12'/>
### Page 12: Population Genomics 4: Admixture and Population Structure Continued

First thing is to grep and get freqs for all three populations like at the end of last class and use scp to move them to my working directory so I can work with them in R.

ip0af52337:~ ethanthibault$ cd /Users/ethanthibault/Documents/UVM_2018/PBIO381/PBIO_381_Notebook 
ip0af52337:PBIO_381_Notebook ethanthibault$ scp eathibau@pbio381.uvm.edu:~/myresults/*frq .
eathibau@pbio381.uvm.edu's password: 
IT.frq                                        100% 5096KB   5.0MB/s   00:00    
NC.frq                                        100% 4844KB   4.9MB/s   00:00    
WA.frq                                        100% 4958KB   5.0MB/s   00:00    
ip0af52337:PBIO_381_Notebook ethanthibault$ 

In new R script we are graphing SFS. There appear to be differences between the three populations in the SFS plots that suggest different population histories. Now we should run admixture to see if there is evidence for distinct ancestries.

Go to terminal, take our vcf file and thin to remove potential linkage disequilibrium, convert from vcf to a .geno file that admixture requires. Then write a bash script to run admixture with K=1 to K=10 to see where the data tells us where population structure exists. Then take that output back into R. (This is the workflow)

Thin to get SNPs to make sure they aren't close together and would fall under linkage disequilibrium.  (--thin 1000) Within a 1000bp window pick a snp and the next snp needs to be at least 1000bp apart.

vcftools --vcf OTAU_2018_reads2snps_DP10GP95_biallelic_MAF01_Miss0.8.vcf.recode.vcf --thin 1000 --recode

In Java run PGDSpider in order to convert out file types into many different kinds of data forms.

Asks for beetle.pop file, beetle.spid file, and then bash script to run commands. (Steve made these files)

copy files into myscripts:

cp /data/project_data/beetles/metadata/beetles.pop .

cp /data/scripts/beetle.spid .

cp /data/scripts/vcf2geno.sh .

Change path with beetle.spid file to where we want output files to go (change mydata to myscripts)

open bash script and the first thing you can change is how many Gigabytes of space you give the program to run. (-Xmx2G)

make bash script to cycle through all 10 K. j gives it 4 threads of CPU to work. cv is cross values. putting the CV values in the txt file allows you to pick the smallest value (least error).

"#!/bin/bash

for K in {1..10}

do

admixture -j 4 --cv 10 ~/myresults/out.recode.vcf.geno $K | tee log${K}.out

done

grep "CV" log*out > chooseK.txt"

Change the permissions:

chmod u+x ADMIX.sh



------
<div id='id-section13'/>
### Page 13: Code for Assignment One

[Here](AssignmentOneCode.html) is a link to the code for assignment one.

------
<div id='id-section14'/>
### Page 14:
------
<div id='id-section15'/>
### Page 15:
------
<div id='id-section16'/>
### Page 16:
------
<div id='id-section17'/>
### Page 17:
------
<div id='id-section18'/>
### Page 18:
------
<div id='id-section19'/>
### Page 19:
------
<div id='id-section20'/>
### Page 20:
------
<div id='id-section21'/>
### Page 21:
------
<div id='id-section22'/>
### Page 22:
------
<div id='id-section23'/>
### Page 23:
------
<div id='id-section24'/>
### Page 24:
------
<div id='id-section25'/>
### Page 25:
------
<div id='id-section26'/>
### Page 26:
------
<div id='id-section27'/>
### Page 27:
------
<div id='id-section28'/>
### Page 28:
------
<div id='id-section29'/>
### Page 29:
------
<div id='id-section30'/>
### Page 30:
------
<div id='id-section31'/>
### Page 31:
------
<div id='id-section32'/>
### Page 32:
------
<div id='id-section33'/>
### Page 33:
------
<div id='id-section34'/>
### Page 34:
------
<div id='id-section35'/>
### Page 35:
------
<div id='id-section36'/>
### Page 36:
------
<div id='id-section37'/>
### Page 37:
------
<div id='id-section38'/>
### Page 38:
------
<div id='id-section39'/>
### Page 39:
------
<div id='id-section40'/>
### Page 40:
------
<div id='id-section41'/>
### Page 41:
------
<div id='id-section42'/>
### Page 42:
------
<div id='id-section43'/>
### Page 43:
------
<div id='id-section44'/>
### Page 44:
------
<div id='id-section45'/>
### Page 45:
------
<div id='id-section46'/>
### Page 46:
------
<div id='id-section47'/>
### Page 47:
------
<div id='id-section48'/>
### Page 48:
------
<div id='id-section49'/>
### Page 49:
------
<div id='id-section50'/>
### Page 50:
------
<div id='id-section51'/>
### Page 51:
------
<div id='id-section52'/>
### Page 52:
------
<div id='id-section53'/>
### Page 53:
------
<div id='id-section54'/>
### Page 54:
------
<div id='id-section55'/>
### Page 55:
------
<div id='id-section56'/>
### Page 56:
------
<div id='id-section57'/>
### Page 57:
------
<div id='id-section58'/>
### Page 58:
------
<div id='id-section59'/>
### Page 59:
------
<div id='id-section60'/>
### Page 60:

------